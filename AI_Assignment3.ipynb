{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0b9214",
   "metadata": {},
   "source": [
    "Task 1\n",
    "    The problem we have is that we have two videos: one with a single moving ball, that has an obstruction in its path where you can't see the ball move in the video, and other video with two moving balls and an obstructuion where both balls overlap in the same position in the video. We have to to make a detector to get the bounding boxes of the balls in both videos when they're on the screen and then use a kalman filter to predict the trajectory of each ball and then make those predictions shown on the video. \n",
    "    The kalman filter is an algorithm that predicts the variables of the next state of a system by calculating the previous state of the system by the relationships of each variable(state covariance matrix) in the state to each other with some adjustments for variables outside the system in the form of a control matrix and vector. There are three other parts to the kalman filter, with the next part being the uncertainty prediction, which is the amount of variance for each prediction representing the error range. This is calculated by the state covariance matrix, its transpose and the previous uncertainty as well as a possiobly noise matrix to added to them to account for noise in the prediction. Now this accounts for the prediction parts but kalman filter is an iterative method so there has to be a way to update the predicted values, in this case the other two parts of the kalman filter: the update step for the predicted state updates the predcited state by accouting for measurements in the system of the predicted variables in the state, now this can be done with a direct measurement or an indirect measurement by accounting for noise from the sensor as well in a state-to-measuremnt matrix. It also uses the kalman gain to calculate the update. The kalman gain is a value that tell us how much each estimate changes with the given measurement, it's calcualted by using the state-to-measurement matrix, stat covariance matrix, and the measurement noise covariance matrix, which helps with noise in indirect measurements. The second part of the update step updates the uncertainty prediction by using the prediction uncertainty, kalman gain, and measurement noise covariance matrix. We need to define a lot of the matrices used in kalman filter oursleves as well as the relationship between variables, measurement, and sensors and give an initial state and unvertainty to start with.\n",
    "    So, I got the detector to work by making the video greyscale on each frame and highlighting the moving objects by making it movement show up as white. Then I limited the area to make the bounding box of the moving objects match the objects we want. This wasn't too much of a trouble as it highlighted the objects pretty well if they were on the screen and in the case of the two moving balls, when they overlapped the bounding box was over their overlapped space. I then got the positions, which for the single ball video was easy as there was only ever one bounding box for us to gather positons from, while for the two moving balls I got both of their positions back, so I then made a formula that got both objects values by looking at the relationship between each moving object and see if it was decreasin or increasing in each frame. This required a starting position for each object to be determined by me. After that I used all of those values returend from the bounding boxes as measurements for the kalman filter, the matricies in the kalman filter was easy to determine as the relationship between measureents and prediction was direct and the rlationship between the variables, each axis was it's own variable, in the state was direct as well. This ended up working well as the kalman filter's predictions lined up with the actual measurements.\n",
    "    The problem happened after this step, when I tried to mark the prediction in the video. I got the frame numbers and all of the positions, if their are less positions than frames, it's either going to be the max value of min value of the frame since the balls are at the edge so I can fill that in. the problem is that I didn't know how to have a drawing showed on a frame by frame basis as it just shows all of the predictions at once on each frame. But it does show the path of the object with the kalman filter and not by detecing objects, as shown when they path beyond the overlap of the moving objects happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f930c",
   "metadata": {},
   "source": [
    "Notes: ### = Code that can run, # = Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab445a9",
   "metadata": {},
   "source": [
    "Object Detection - Single Ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de98467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('C:/Users/poona/Downloads/ball.mp4')\n",
    "od = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=150) #Object detector/Motion analysis\n",
    "#history = How many previous frames are used for the background; The longer then more precise, but less precise if camera moves \n",
    "#varThreshold: Sqaured distance from pixel to sample; The lower the value the higher chance for false positives but more results\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) #Frame count\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217062aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coordinates = [] #For tracker, list of coordinates\n",
    "while(cap.isOpened()):#Loop forever\n",
    "    \n",
    "    ret, frame = cap.read() #Knows if there is a frame and what the frame is\n",
    "    \n",
    "    if ret:   #ret is true if a frame is there, frame is the next frame in the video \n",
    "        \n",
    "        ###height, width, _ = frame.shape\n",
    "        ###print(height,width) #This was to get the area to cut down on when performing the motion analysis\n",
    "        roi = frame[180:360,1:960] #Portion of the frame being used\n",
    "\n",
    "        mask = od.apply(roi) #Applying the motion analysis to the frame: black if no movement, white if movement\n",
    "        a, mask = cv2.threshold(mask,254,255,cv2.THRESH_BINARY) #Removes all non-white colors - Good for shadows\n",
    "        #arguments: Frame, Threshold value, Max value, Function that replaces it(Binary function in this case)\n",
    "        \n",
    "        contours, a = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #Boundary box\n",
    "        #arguments for findContours: Image, Mode, Method/Algorithm that keeps the pixels(In this case all unique values only)\n",
    "        #The mode gets all of the bounday box pixels\n",
    "\n",
    "        for i in contours: #Goes by each frame\n",
    "            area = cv2.contourArea(i) #Calculate area and remove small elements\n",
    "            if area > 1400: \n",
    "                ###cv2.drawContours(roi,[i],-1,(0,255,0),2) #Draws boundary lines on the cropped frame\n",
    "                #Arguments are: Frame, Contours, Contour index(For all put -1) , Color, Thickness\n",
    "                \n",
    "                x,y,h,w = cv2.boundingRect(i)#Draws a rectangle around the objects\n",
    "                cv2.rectangle(roi,(x,y),(x+h,y+w),(0,255,0),3) #Draws a rectangle on cropped image\n",
    "                #Arguments are: Image, Vertices 1, Verticies 2(The opposite side), Color, Line thickness\n",
    "                Coordinates.append([x,y,h,w]) #For Tracker, adds the coordinates to the list\n",
    "            \n",
    "        \n",
    "        cv2.imshow(\"Frame\", frame) #Shows the frame from VideoCapture\n",
    "        ###cv2.imshow(\"Mask\",mask) #Shows frame after motion analysis was done to it\n",
    "        ###cv2.imshow(\"ROI\",roi) #Shows the frame after area was cropped out\n",
    "\n",
    "        k = cv2.waitKey(200) #Time in milliseconds for each frame to pass\n",
    "        if k == 27: #ESC key\n",
    "            break #Ends loop\n",
    "    else:\n",
    "        break\n",
    "cap.release() #Releases camera/video\n",
    "cv2.destroyAllWindows() #Closes all open windows that showed frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82832096",
   "metadata": {},
   "source": [
    "Object Tracker - Single Ball - Prediction with Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeff37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coordarray = np.array(Coordinates) #Grabbing the Coordinates and making them into an array\n",
    "xvals=np.zeros(31) #Empty array for x values\n",
    "yvals=np.zeros(31) #Empty array for y values\n",
    "hvals=np.zeros(31) #Empty array for y values\n",
    "wvals=np.zeros(31) #Empty array for y values\n",
    "\n",
    "for i in range(0,31): #Cycles through each placement in the x values array\n",
    "    xvals[i]=Coordarray[i,0] #Updates it with the corresponding x value in the coordinates array\n",
    "\n",
    "for i in range(0,31): #Cycles through each placement in the y values array\n",
    "    yvals[i]=Coordarray[i,1] #Updates it with the corresponding y value in the coordinates array\n",
    "    \n",
    "for i in range(0,31): #Cycles through each placement in the h values array\n",
    "    hvals[i]=Coordarray[i,2] #Updates it with the corresponding h value in the coordinates array\n",
    "    \n",
    "for i in range(0,31): #Cycles through each placement in the w values array\n",
    "    wvals[i]=Coordarray[i,3] #Updates it with the corresponding w value in the coordinates array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04ef939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[960.]]\n",
      "[[884.]]\n",
      "[[889.5]]\n",
      "[[835.25]]\n",
      "[[846.125]]\n",
      "[[765.5625]]\n",
      "[[712.78125]]\n",
      "[[674.890625]]\n",
      "[[644.9453125]]\n",
      "[[622.47265625]]\n",
      "[[610.73632812]]\n",
      "[[597.36816406]]\n",
      "[[464.68408203]]\n",
      "[[387.84204102]]\n",
      "[[339.42102051]]\n",
      "[[302.71051025]]\n",
      "[[276.85525513]]\n",
      "[[253.92762756]]\n",
      "[[230.96381378]]\n",
      "[[210.48190689]]\n",
      "[[183.74095345]]\n",
      "[[167.37047672]]\n",
      "[[149.18523836]]\n",
      "[[130.59261918]]\n",
      "[[110.79630959]]\n",
      "[[81.8981548]]\n",
      "[[67.4490774]]\n",
      "[[54.2245387]]\n",
      "[[35.11226935]]\n",
      "[[17.55613467]]\n",
      "[[8.77806734]]\n"
     ]
    }
   ],
   "source": [
    "#I did not need some of these, but was messing around with them so I just left them defined\n",
    "#I believe 1's works for them because the measured values are waht we want and not some indirect measure\n",
    "SCM=np.identity(1) #State Covariance Matrix\n",
    "Q = np.ones((1,1)) #Process Noise Covariance Matrix\n",
    "H = np.ones((1,1)) #Representation of Sensor\n",
    "R = np.ones((1,1)) #Measurement Noise Covariance Matrix\n",
    "zx=xvals #Measured values\n",
    "zy=yvals #Measured values\n",
    "zh=hvals #Measured values\n",
    "zw=wvals #Measured values\n",
    "ite=31 #Iterations\n",
    "xpred=960 #Initial State\n",
    "ypred=45 #Initial State\n",
    "hpred=100\n",
    "wpred=100\n",
    "xtrack=np.zeros(ite) #Array to get all of the predictions\n",
    "ytrack=np.zeros(ite)\n",
    "htrack=np.zeros(ite)\n",
    "wtrack=np.zeros(ite)\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    xpred=SCM*xpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*xpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    print(xpred) #Prints the predicted values ##Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    xupdate=xpred+K*(zx[i]-H*xpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    xpred=xupdate #Updates the predicted value for the next iteration\n",
    "    xtrack[i]=xupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    ypred=SCM*ypred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*xpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(ypred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    yupdate=ypred+K*(zy[i]-H*ypred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    ypred=yupdate #Updates the predicted value for the next iteration\n",
    "    ytrack[i]=yupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    hpred=SCM*hpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*hpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(hpred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    hupdate=hpred+K*(zh[i]-H*hpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    hpred=hupdate #Updates the predicted value for the next iteration\n",
    "    htrack[i]=hupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    wpred=SCM*wpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*wpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(wpred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    wupdate=wpred+K*(zw[i]-H*wpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    wpred=wupdate #Updates the predicted value for the next iteration\n",
    "    wtrack[i]=wupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d649c5c",
   "metadata": {},
   "source": [
    "Object Tracker - Single Ball - Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f069e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialx=np.append(xtrack,np.zeros(20))\n",
    "trialy=np.append(ytrack,np.zeros(20))\n",
    "trialh=np.append(htrack,np.zeros(20))\n",
    "trialw=np.append(wtrack,np.zeros(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4280506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('C:/Users/poona/Downloads/ball.mp4')\n",
    "od = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=150) #Object detector/Motion analysis\n",
    "#history = How many previous frames are used for the background; The longer then more precise, but less precise if camera moves \n",
    "#varThreshold: Sqaured distance from pixel to sample; The lower the value the higher chance for false positives but more results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c252dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(cap.isOpened()):#Loop forever\n",
    "    \n",
    "    ret, frame = cap.read() #Knows if there is a frame and what the frame is\n",
    "    \n",
    "    if ret:   #ret is true if a frame is there, frame is the next frame in the video \n",
    "        \n",
    "        ###height, width, _ = frame.shape\n",
    "        ###print(height,width) #This was to get the area to cut down on when performing the motion analysis\n",
    "        roi = frame[180:360,1:960] #Portion of the frame being used\n",
    "\n",
    "        mask = od.apply(roi) #Applying the motion analysis to the frame: black if no movement, white if movement\n",
    "        a, mask = cv2.threshold(mask,254,255,cv2.THRESH_BINARY) #Removes all non-white colors - Good for shadows\n",
    "        #arguments: Frame, Threshold value, Max value, Function that replaces it(Binary function in this case)\n",
    "        \n",
    "        contours, a = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #Boundary box\n",
    "        #arguments for findContours: Image, Mode, Method/Algorithm that keeps the pixels(In this case all unique values only)\n",
    "        #The mode gets all of the bounday box pixels\n",
    "\n",
    "        for i in contours: #Goes by each frame\n",
    "            area = cv2.contourArea(i) #Calculate area and remove small elements\n",
    "            if area > 1400: \n",
    "                ###cv2.drawContours(roi,[i],-1,(0,255,0),2) #Draws boundary lines on the cropped frame\n",
    "                #Arguments are: Frame, Contours, Contour index(For all put -1) , Color, Thickness\n",
    "                \n",
    "                x,y,h,w = cv2.boundingRect(i)#Draws a rectangle around the objects\n",
    "                ###cv2.rectangle(roi,(x,y),(x+h,y+w),(0,255,0),3) #Draws a rectangle on cropped image\n",
    "                #cv2.circle(roi, (trialx[i], trialy[i]), radius=0, color=(0, 0, 255), thickness=-1)\n",
    "                #Arguments are: Image, Vertices 1, Verticies 2(The opposite side), Color, Line thickness\n",
    "        \n",
    "        for i in range(0,51):\n",
    "            cv2.rectangle(roi,(int(trialx[i]),int(trialy[i])),(int(trialx[i])+int(trialh[i]),int(trialy[i])+int(trialw[i])),(0,255,0),3)\n",
    "        \n",
    "        cv2.imshow(\"Frame\", frame) #Shows the frame from VideoCapture\n",
    "        ###cv2.imshow(\"Mask\",mask) #Shows frame after motion analysis was done to it\n",
    "        ###cv2.imshow(\"ROI\",roi) #Shows the frame after area was cropped out\n",
    "\n",
    "        k = cv2.waitKey(200) #Time in milliseconds for each frame to pass\n",
    "        if k == 27: #ESC key\n",
    "            break #Ends loop\n",
    "    else:\n",
    "        break\n",
    "cap.release() #Releases camera/video\n",
    "cv2.destroyAllWindows() #Closes all open windows that showed frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cac631",
   "metadata": {},
   "source": [
    "Object Detection - Multiple Ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c36892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "cap= cv2.VideoCapture('C:/Users/poona/Downloads/objectTracking_examples_multiObject.avi') \n",
    "od = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=90) #Object detector/Motion analysis\n",
    "#history = How many previous frames are used for the background; The longer then more precise, but less precise if camera moves \n",
    "#varThreshold: Sqaured distance from pixel to sample; The lower the value the higher chance for false positives but more results\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) #Frame count\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47ae93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiCoordinates = [] #For tracker, list of coordinates\n",
    "while(cap.isOpened()):#Loop forever\n",
    "    \n",
    "    ret, frame = cap.read() #Knows if there is a frame and what the frame is\n",
    "    \n",
    "    if ret:   #ret is true if a frame is there, frame is the next frame in the video \n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        ###print(height,width) #This was to get the area to cut down on when performing the motion analysis\n",
    "        roi = frame[115:245,1:640] #Portion of the frame being used\n",
    "\n",
    "        mask = od.apply(roi) #Applying the motion analysis to the frame: black if no movement, white if movement\n",
    "        a, mask = cv2.threshold(mask,254,255,cv2.THRESH_BINARY) #Removes all non-white colors - Good for shadows\n",
    "        #arguments: Frame, Threshold value, Max value, Function that replaces it(Binary function in this case)\n",
    "        \n",
    "        contours, a = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #Boundary box\n",
    "        #arguments for findContours: Image, Mode, Method/Algorithm that keeps the pixels(In this case all unique values only)\n",
    "        #The mode gets all of the bounday box pixels\n",
    "\n",
    "        for i in contours: #Goes by each frame\n",
    "            area = cv2.contourArea(i) #Calculate area and remove small elements\n",
    "            if area > 1400: \n",
    "                ###cv2.drawContours(roi,[i],-1,(0,255,0),2) #Draws boundary lines on the cropped frame\n",
    "                #Arguments are: Frame, Contours, Contour index(For all put -1) , Color, Thickness\n",
    "                \n",
    "                x,y,h,w = cv2.boundingRect(i)#Draws a rectangle around the objects\n",
    "                cv2.rectangle(roi,(x,y),(x+h,y+w),(0,255,0),3) #Draws a rectangle on cropped image\n",
    "                #Arguments are: Image, Vertices 1, Verticies 2(The opposite side), Color, Line thickness\n",
    "                MultiCoordinates.append([x,y,h,w]) #For Tracker, adds the coordinates to the list\n",
    "        \n",
    "        cv2.imshow(\"Frame\", frame) #Shows the frame from VideoCapture\n",
    "        ###cv2.imshow(\"Mask\",mask) #Shows frame after motion analysis was done to it\n",
    "        ###cv2.imshow(\"ROI\",roi) #Shows the frame after area was cropped out\n",
    "\n",
    "        k = cv2.waitKey(200) #Time in milliseconds for each frame to pass\n",
    "        if k == 27: #ESC key\n",
    "            break #Ends loop\n",
    "    else:\n",
    "        break\n",
    "cap.release() #Releases camera/video\n",
    "cv2.destroyAllWindows() #Closes all open windows that showed frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dad26d",
   "metadata": {},
   "source": [
    "Object Tracker - Multiple Ball - Prediction with Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac40540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCoordarray=np.array(MultiCoordinates)\n",
    "xfirst=np.zeros(52) #Empty vector to get a vector with the index but it wil be padded with zeros\n",
    "xfirst[0]=566 #Initial value for the first object\n",
    "initialx=xfirst[0] #Constant value of the first index in the vector\n",
    "for i in range(0,52): #Checking for values\n",
    "    if MCoordarray[i,0]<initialx:\n",
    "         if (initialx-MCoordarray[i,0])<50:\n",
    "            xfirst[i]=MCoordarray[i,0]\n",
    "            initialx=xfirst[i] \n",
    "index = np.where(xfirst != 0)[0] #Index for first object\n",
    "\n",
    "xfo=np.zeros(27) #First object positions\n",
    "for i in range(0,27):\n",
    "    xfo[i]=index[i]\n",
    "\n",
    "allv=np.zeros(52) #Vector with all values\n",
    "for i in range(0,52):\n",
    "    allv[i]=i\n",
    "\n",
    "xso= np.array(list(set(allv)-set(xfo))) #Second object positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06064410",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfvals=np.zeros(27) #Empty array for x values\n",
    "yfvals=np.zeros(27) #Empty array for y values\n",
    "hfvals=np.zeros(27) #Empty array for y values\n",
    "wfvals=np.zeros(27) #Empty array for y values\n",
    "\n",
    "for i in range(0,27): #Cycles through each placement in the x values array\n",
    "    xfvals[i]=MCoordarray[int(xfo[i]),0] #Updates it with the corresponding x value in the coordinates array\n",
    "\n",
    "for i in range(0,27): #Cycles through each placement in the y values array\n",
    "    yfvals[i]=MCoordarray[int(xfo[i]),1] #Updates it with the corresponding y value in the coordinates array\n",
    "    \n",
    "for i in range(0,27): #Cycles through each placement in the h values array\n",
    "    hfvals[i]=MCoordarray[int(xfo[i]),2] #Updates it with the corresponding h value in the coordinates array\n",
    "    \n",
    "for i in range(0,27): #Cycles through each placement in the w values array\n",
    "    wfvals[i]=MCoordarray[int(xfo[i]),3] #Updates it with the corresponding w value in the coordinates array\n",
    "    \n",
    "xsvals=np.zeros(25) #Empty array for x values\n",
    "ysvals=np.zeros(25) #Empty array for y values\n",
    "hsvals=np.zeros(25) #Empty array for y values\n",
    "wsvals=np.zeros(27) #Empty array for y values\n",
    "\n",
    "for i in range(0,25): #Cycles through each placement in the x values array\n",
    "    xsvals[i]=MCoordarray[int(xso[i]),0] #Updates it with the corresponding x value in the coordinates array\n",
    "\n",
    "for i in range(0,25): #Cycles through each placement in the y values array\n",
    "    ysvals[i]=MCoordarray[int(xso[i]),1] #Updates it with the corresponding y value in the coordinates array\n",
    "    \n",
    "for i in range(0,25): #Cycles through each placement in the h values array\n",
    "    hsvals[i]=MCoordarray[int(xso[i]),2] #Updates it with the corresponding h value in the coordinates array\n",
    "    \n",
    "for i in range(0,25): #Cycles through each placement in the w values array\n",
    "    wsvals[i]=MCoordarray[int(xso[i]),3] #Updates it with the corresponding w value in the coordinates array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e889e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[600.]]\n",
      "[[583.]]\n",
      "[[562.]]\n",
      "[[538.5]]\n",
      "[[516.75]]\n",
      "[[494.375]]\n",
      "[[472.1875]]\n",
      "[[450.59375]]\n",
      "[[428.796875]]\n",
      "[[407.3984375]]\n",
      "[[386.19921875]]\n",
      "[[365.59960938]]\n",
      "[[345.29980469]]\n",
      "[[325.14990234]]\n",
      "[[291.57495117]]\n",
      "[[269.28747559]]\n",
      "[[240.14373779]]\n",
      "[[216.0718689]]\n",
      "[[195.03593445]]\n",
      "[[175.51796722]]\n",
      "[[156.25898361]]\n",
      "[[137.62949181]]\n",
      "[[119.3147459]]\n",
      "[[101.15737295]]\n",
      "[[83.07868648]]\n",
      "[[64.53934324]]\n",
      "[[46.26967162]]\n"
     ]
    }
   ],
   "source": [
    "#First object predictions\n",
    "#I did not need some of these, but was messing around with them so I just left them defined\n",
    "#I believe 1's works for them because the measured values are waht we want and not some indirect measure\n",
    "SCM=np.identity(1) #State Covariance Matrix\n",
    "Q = np.ones((1,1)) #Process Noise Covariance Matrix\n",
    "H = np.ones((1,1)) #Representation of Sensor\n",
    "R = np.ones((1,1)) #Measurement Noise Covariance Matrix\n",
    "zx=xfvals #Measured values\n",
    "zy=yfvals #Measured values\n",
    "zh=hfvals #Measured values\n",
    "zw=wfvals #Measured values\n",
    "ite=27 #Iterations\n",
    "xpred=600 #Initial State\n",
    "ypred=10 #Initial State\n",
    "hpred=100\n",
    "wpred=100\n",
    "xftrack=np.zeros(ite) #Array to get all of the predictions\n",
    "yftrack=np.zeros(ite)\n",
    "hftrack=np.zeros(ite)\n",
    "wftrack=np.zeros(ite)\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    xpred=SCM*xpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*xpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    print(xpred) #Prints the predicted values ##Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    xupdate=xpred+K*(zx[i]-H*xpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    xpred=xupdate #Updates the predicted value for the next iteration\n",
    "    xftrack[i]=xupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    ypred=SCM*ypred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*xpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(ypred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    yupdate=ypred+K*(zy[i]-H*ypred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    ypred=yupdate #Updates the predicted value for the next iteration\n",
    "    yftrack[i]=yupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    hpred=SCM*hpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*hpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(hpred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    hupdate=hpred+K*(zh[i]-H*hpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    hpred=hupdate #Updates the predicted value for the next iteration\n",
    "    hftrack[i]=hupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    wpred=SCM*wpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*wpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(wpred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    wupdate=wpred+K*(zw[i]-H*wpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    wpred=wupdate #Updates the predicted value for the next iteration\n",
    "    wftrack[i]=wupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2b2962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[8.]]\n",
      "[[24.5]]\n",
      "[[38.75]]\n",
      "[[45.875]]\n",
      "[[68.4375]]\n",
      "[[90.21875]]\n",
      "[[110.609375]]\n",
      "[[130.8046875]]\n",
      "[[143.90234375]]\n",
      "[[166.95117188]]\n",
      "[[187.47558594]]\n",
      "[[209.23779297]]\n",
      "[[230.11889648]]\n",
      "[[248.05944824]]\n",
      "[[269.52972412]]\n",
      "[[290.26486206]]\n",
      "[[311.13243103]]\n",
      "[[447.56621552]]\n",
      "[[523.28310776]]\n",
      "[[561.64155388]]\n",
      "[[588.32077694]]\n"
     ]
    }
   ],
   "source": [
    "#Second object predictions\n",
    "#I did not need some of these, but was messing around with them so I just left them defined\n",
    "#I believe 1's works for them because the measured values are waht we want and not some indirect measure\n",
    "SCM=np.identity(1) #State Covariance Matrix\n",
    "Q = np.ones((1,1)) #Process Noise Covariance Matrix\n",
    "H = np.ones((1,1)) #Representation of Sensor\n",
    "R = np.ones((1,1)) #Measurement Noise Covariance Matrix\n",
    "zx=xvals[::-1] #Measured values - Had to reverse them since the index was from the other side of the frame\n",
    "zy=yvals[::-1] #Measured values\n",
    "zh=hvals[::-1] #Measured values\n",
    "zw=wvals[::-1] #Measured values\n",
    "ite=25 #Iterations\n",
    "xpred=0 #Initial State\n",
    "ypred=10 #Initial State\n",
    "hpred=100\n",
    "wpred=100\n",
    "xstrack=np.zeros(ite) #Array to get all of the predictions\n",
    "ystrack=np.zeros(ite)\n",
    "hstrack=np.zeros(ite)\n",
    "wstrack=np.zeros(ite)\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    xpred=SCM*xpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*xpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    print(xpred) #Prints the predicted values ##Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    xupdate=xpred+K*(zx[i]-H*xpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    xpred=xupdate #Updates the predicted value for the next iteration\n",
    "    xstrack[i]=xupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    ypred=SCM*ypred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*xpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(ypred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    yupdate=ypred+K*(zy[i]-H*ypred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    ypred=yupdate #Updates the predicted value for the next iteration\n",
    "    ystrack[i]=yupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    hpred=SCM*hpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*hpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(hpred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    hupdate=hpred+K*(zh[i]-H*hpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    hpred=hupdate #Updates the predicted value for the next iteration\n",
    "    hstrack[i]=hupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance\n",
    "\n",
    "for i in range(0,ite): #Cycles through number of iterations\n",
    "    \n",
    "    #Kalman Gain\n",
    "    K=(SCM*H.T)/(H*SCM*H.T+R) #Relationship between prediction and measurement, only new variable is the measurement noise covariance matrix\n",
    "\n",
    "    #Prediction Steps\n",
    "    wpred=SCM*wpred #Prediction of the value by multiplying the previous or initial value by the state\n",
    "    #No control matrix or vecotor was added for the state prediction\n",
    "    \n",
    "    Ppred=SCM*wpred*SCM.T + Q #Covariance prediction\n",
    "    #Calculated by multiplying the state covariance matrix and its transpose by the predicted state value\n",
    "    \n",
    "    ###print(wpred) #Prints the predicted values #Pretty close to the actual\n",
    "    \n",
    "    #Update Steps\n",
    "    wupdate=wpred+K*(zw[i]-H*wpred) #Updates the predicted state\n",
    "    #Accounts for a measured value,a wight on the current estimate called the Kalman Gain, \n",
    "    #and the sensor measurement represenation\n",
    "    \n",
    "    wpred=wupdate #Updates the predicted value for the next iteration\n",
    "    wstrack[i]=wupdate #Updates predicted values to an array\n",
    "    Pupdate=SCM-K*H*SCM #Covariance prediction based on the Kalman Gain, sensor reprsentation, and state covariance matrix\n",
    "    Ppred=Pupdate #Updates the predicted covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cc164",
   "metadata": {},
   "source": [
    "Object Tracker - Multiple Ball - Video - Object 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17c33d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialfx=np.append(xftrack,np.zeros(14))\n",
    "trialfy=np.append(yftrack,np.zeros(14))\n",
    "trialfh=np.append(hftrack,np.zeros(14))\n",
    "trialfw=np.append(wftrack,np.zeros(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c662faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap= cv2.VideoCapture('C:/Users/poona/Downloads/objectTracking_examples_multiObject.avi') \n",
    "od = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=150) #Object detector/Motion analysis\n",
    "#history = How many previous frames are used for the background; The longer then more precise, but less precise if camera moves \n",
    "#varThreshold: Sqaured distance from pixel to sample; The lower the value the higher chance for false positives but more results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25ccf6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(cap.isOpened()):#Loop forever\n",
    "    \n",
    "    ret, frame = cap.read() #Knows if there is a frame and what the frame is\n",
    "    \n",
    "    if ret:   #ret is true if a frame is there, frame is the next frame in the video \n",
    "        \n",
    "        ###height, width, _ = frame.shape\n",
    "        ###print(height,width) #This was to get the area to cut down on when performing the motion analysis\n",
    "        roi = frame[115:245,1:640] #Portion of the frame being used\n",
    "\n",
    "        mask = od.apply(roi) #Applying the motion analysis to the frame: black if no movement, white if movement\n",
    "        a, mask = cv2.threshold(mask,254,255,cv2.THRESH_BINARY) #Removes all non-white colors - Good for shadows\n",
    "        #arguments: Frame, Threshold value, Max value, Function that replaces it(Binary function in this case)\n",
    "        \n",
    "        contours, a = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #Boundary box\n",
    "        #arguments for findContours: Image, Mode, Method/Algorithm that keeps the pixels(In this case all unique values only)\n",
    "        #The mode gets all of the bounday box pixels\n",
    "\n",
    "        for i in contours: #Goes by each frame\n",
    "            area = cv2.contourArea(i) #Calculate area and remove small elements\n",
    "            if area > 1400: \n",
    "                ###cv2.drawContours(roi,[i],-1,(0,255,0),2) #Draws boundary lines on the cropped frame\n",
    "                #Arguments are: Frame, Contours, Contour index(For all put -1) , Color, Thickness\n",
    "                \n",
    "                x,y,h,w = cv2.boundingRect(i)#Draws a rectangle around the objects\n",
    "                ###cv2.rectangle(roi,(x,y),(x+h,y+w),(0,255,0),3) #Draws a rectangle on cropped image\n",
    "                #cv2.circle(roi, (trialx[i], trialy[i]), radius=0, color=(0, 0, 255), thickness=-1)\n",
    "                #Arguments are: Image, Vertices 1, Verticies 2(The opposite side), Color, Line thickness\n",
    "        \n",
    "        for i in range(0,41):\n",
    "            cv2.rectangle(roi,(int(trialfx[i]),int(trialfy[i])),(int(trialfx[i])+int(trialfh[i]),int(trialfy[i])+int(trialfw[i])),(0,255,0),3)\n",
    "        \n",
    "        cv2.imshow(\"Frame\", frame) #Shows the frame from VideoCapture\n",
    "        ###cv2.imshow(\"Mask\",mask) #Shows frame after motion analysis was done to it\n",
    "        ###cv2.imshow(\"ROI\",roi) #Shows the frame after area was cropped out\n",
    "\n",
    "        k = cv2.waitKey(200) #Time in milliseconds for each frame to pass\n",
    "        if k == 27: #ESC key\n",
    "            break #Ends loop\n",
    "    else:\n",
    "        break\n",
    "cap.release() #Releases camera/video\n",
    "cv2.destroyAllWindows() #Closes all open windows that showed frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200f41f",
   "metadata": {},
   "source": [
    "Object Tracker - Multiple Ball - Video - Object 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfdf3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialsx=np.append(xstrack,np.zeros(16))\n",
    "trialsy=np.append(ystrack,np.zeros(16))\n",
    "trialsh=np.append(hstrack,np.zeros(16))\n",
    "trialsw=np.append(wstrack,np.zeros(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5254721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap= cv2.VideoCapture('C:/Users/poona/Downloads/objectTracking_examples_multiObject.avi') \n",
    "od = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=150) #Object detector/Motion analysis\n",
    "#history = How many previous frames are used for the background; The longer then more precise, but less precise if camera moves \n",
    "#varThreshold: Sqaured distance from pixel to sample; The lower the value the higher chance for false positives but more results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae69842",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(cap.isOpened()):#Loop forever\n",
    "    \n",
    "    ret, frame = cap.read() #Knows if there is a frame and what the frame is\n",
    "    \n",
    "    if ret:   #ret is true if a frame is there, frame is the next frame in the video \n",
    "        \n",
    "        ###height, width, _ = frame.shape\n",
    "        ###print(height,width) #This was to get the area to cut down on when performing the motion analysis\n",
    "        roi = frame[115:245,1:640] #Portion of the frame being used\n",
    "\n",
    "        mask = od.apply(roi) #Applying the motion analysis to the frame: black if no movement, white if movement\n",
    "        a, mask = cv2.threshold(mask,254,255,cv2.THRESH_BINARY) #Removes all non-white colors - Good for shadows\n",
    "        #arguments: Frame, Threshold value, Max value, Function that replaces it(Binary function in this case)\n",
    "        \n",
    "        contours, a = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #Boundary box\n",
    "        #arguments for findContours: Image, Mode, Method/Algorithm that keeps the pixels(In this case all unique values only)\n",
    "        #The mode gets all of the bounday box pixels\n",
    "\n",
    "        for i in contours: #Goes by each frame\n",
    "            area = cv2.contourArea(i) #Calculate area and remove small elements\n",
    "            if area > 1400: \n",
    "                ###cv2.drawContours(roi,[i],-1,(0,255,0),2) #Draws boundary lines on the cropped frame\n",
    "                #Arguments are: Frame, Contours, Contour index(For all put -1) , Color, Thickness\n",
    "                \n",
    "                x,y,h,w = cv2.boundingRect(i)#Draws a rectangle around the objects\n",
    "                ###cv2.rectangle(roi,(x,y),(x+h,y+w),(0,255,0),3) #Draws a rectangle on cropped image\n",
    "                #cv2.circle(roi, (trialx[i], trialy[i]), radius=0, color=(0, 0, 255), thickness=-1)\n",
    "                #Arguments are: Image, Vertices 1, Verticies 2(The opposite side), Color, Line thickness\n",
    "        \n",
    "        for i in range(0,41):\n",
    "            cv2.rectangle(roi,(int(trialsx[i]),int(trialsy[i])),(int(trialsx[i])+int(trialsh[i]),int(trialsy[i])+int(trialsw[i])),(0,255,0),3)\n",
    "        \n",
    "        cv2.imshow(\"Frame\", frame) #Shows the frame from VideoCapture\n",
    "        ###cv2.imshow(\"Mask\",mask) #Shows frame after motion analysis was done to it\n",
    "        ###cv2.imshow(\"ROI\",roi) #Shows the frame after area was cropped out\n",
    "\n",
    "        k = cv2.waitKey(200) #Time in milliseconds for each frame to pass\n",
    "        if k == 27: #ESC key\n",
    "            break #Ends loop\n",
    "    else:\n",
    "        break\n",
    "cap.release() #Releases camera/video\n",
    "cv2.destroyAllWindows() #Closes all open windows that showed frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1daa68",
   "metadata": {},
   "source": [
    "Object Tracker - Multiple Ball - Video - All Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04d56099",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap= cv2.VideoCapture('C:/Users/poona/Downloads/objectTracking_examples_multiObject.avi') \n",
    "od = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=150) #Object detector/Motion analysis\n",
    "#history = How many previous frames are used for the background; The longer then more precise, but less precise if camera moves \n",
    "#varThreshold: Sqaured distance from pixel to sample; The lower the value the higher chance for false positives but more results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d17c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(cap.isOpened()):#Loop forever\n",
    "    \n",
    "    ret, frame = cap.read() #Knows if there is a frame and what the frame is\n",
    "    \n",
    "    if ret:   #ret is true if a frame is there, frame is the next frame in the video \n",
    "        \n",
    "        ###height, width, _ = frame.shape\n",
    "        ###print(height,width) #This was to get the area to cut down on when performing the motion analysis\n",
    "        roi = frame[115:245,1:640] #Portion of the frame being used\n",
    "\n",
    "        mask = od.apply(roi) #Applying the motion analysis to the frame: black if no movement, white if movement\n",
    "        a, mask = cv2.threshold(mask,254,255,cv2.THRESH_BINARY) #Removes all non-white colors - Good for shadows\n",
    "        #arguments: Frame, Threshold value, Max value, Function that replaces it(Binary function in this case)\n",
    "        \n",
    "        contours, a = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #Boundary box\n",
    "        #arguments for findContours: Image, Mode, Method/Algorithm that keeps the pixels(In this case all unique values only)\n",
    "        #The mode gets all of the bounday box pixels\n",
    "\n",
    "        for i in contours: #Goes by each frame\n",
    "            area = cv2.contourArea(i) #Calculate area and remove small elements\n",
    "            if area > 1400: \n",
    "                ###cv2.drawContours(roi,[i],-1,(0,255,0),2) #Draws boundary lines on the cropped frame\n",
    "                #Arguments are: Frame, Contours, Contour index(For all put -1) , Color, Thickness\n",
    "                \n",
    "                x,y,h,w = cv2.boundingRect(i)#Draws a rectangle around the objects\n",
    "                ###cv2.rectangle(roi,(x,y),(x+h,y+w),(0,255,0),3) #Draws a rectangle on cropped image\n",
    "                #cv2.circle(roi, (trialx[i], trialy[i]), radius=0, color=(0, 0, 255), thickness=-1)\n",
    "                #Arguments are: Image, Vertices 1, Verticies 2(The opposite side), Color, Line thickness\n",
    "        \n",
    "        for i in range(0,41):\n",
    "            cv2.rectangle(roi,(int(trialfx[i]),int(trialfy[i])),(int(trialfx[i])+int(trialfh[i]),int(trialfy[i])+int(trialfw[i])),(0,255,0),3)\n",
    "            cv2.rectangle(roi,(int(trialsx[i]),int(trialsy[i])),(int(trialsx[i])+int(trialsh[i]),int(trialsy[i])+int(trialsw[i])),(255,0,0),3)\n",
    "            \n",
    "        cv2.imshow(\"Frame\", frame) #Shows the frame from VideoCapture\n",
    "        ###cv2.imshow(\"Mask\",mask) #Shows frame after motion analysis was done to it\n",
    "        ###cv2.imshow(\"ROI\",roi) #Shows the frame after area was cropped out\n",
    "\n",
    "        k = cv2.waitKey(200) #Time in milliseconds for each frame to pass\n",
    "        if k == 27: #ESC key\n",
    "            break #Ends loop\n",
    "    else:\n",
    "        break\n",
    "cap.release() #Releases camera/video\n",
    "cv2.destroyAllWindows() #Closes all open windows that showed frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404cdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
